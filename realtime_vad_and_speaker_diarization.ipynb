{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fb941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ðŸš€ Realtime Voice Activity Detection (VAD) and Speaker Diarization\n",
    "# Author: Mr.Jack (https://github.com/Mr-Jack-Tung)\n",
    "# Date: 2025-11-02\n",
    "# Description: HÆ°á»›ng dáº«n xÃ¢y dá»±ng há»‡ thá»‘ng VAD (Voice Activity Detection) vÃ  nháº­n diá»‡n ngÆ°á»i nÃ³i (Speaker Diarization) thá»i gian thá»±c sá»­ dá»¥ng Python vÃ  cÃ¡c thÆ° viá»‡n mÃ£ nguá»“n má»Ÿ (\"pyannote/speaker-diarization\").\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acd89d2",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4106e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CÃ i Ä‘áº·t ffmpeg trÃªn MacOS báº±ng homebrew\n",
    "!brew install -q ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "075d1d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q numpy sounddevice webrtcvad soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e06ce45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c72276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb9e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28bfb721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CÃ i Ä‘áº·t thÃªm torch Ä‘á»ƒ há»— trá»£ pyannote.audio\n",
    "!pip install -q torch torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd89f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pyannote.audio for speaker diarization\n",
    "!pip install -q pyannote.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "315f706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q resemblyzer scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70c62a0",
   "metadata": {},
   "source": [
    "## Imports & Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95569f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import queue\n",
    "import threading\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Dict\n",
    "from collections import deque\n",
    "import webrtcvad\n",
    "import time\n",
    "import whisper\n",
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "# pyannote.audio may be optional; import safely\n",
    "try:\n",
    "    from pyannote.audio import Pipeline\n",
    "    print(\"âœ“ pyannote.audio imported successfully\")\n",
    "except Exception as e:\n",
    "    Pipeline = None\n",
    "    print(f\"! pyannote.audio not available: {e}\")\n",
    "\n",
    "# Optional local diarization libraries (resemblyzer + sklearn)\n",
    "try:\n",
    "    from resemblyzer import VoiceEncoder\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    print(\"âœ“ resemblyzer and sklearn imported successfully\")\n",
    "except Exception as e:\n",
    "    VoiceEncoder = None\n",
    "    cosine_similarity = None\n",
    "    print(f\"! local diarization not available: {e} - run: pip install resemblyzer scikit-learn\")\n",
    "\n",
    "@dataclass\n",
    "class SpeechSegment:\n",
    "    samples: np.ndarray\n",
    "    start_time: float\n",
    "    end_time: float\n",
    "    confidence: float\n",
    "    transcript: str = \"\"\n",
    "    speaker_id: str = \"\"  # Added speaker identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8607bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealtimeVAD:\n",
    "    def __init__(self, \n",
    "                 sample_rate: int = 16000,\n",
    "                 chunk_duration_ms: int = 30,\n",
    "                 padding_duration_ms: int = 300,\n",
    "                 silence_duration_ms: int = 500,\n",
    "                 vad_sensitivity: int = 3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sample_rate: Pháº£i lÃ  16000 cho WebRTC VAD\n",
    "            chunk_duration_ms: Äá»™ dÃ i má»—i chunk (30ms lÃ  tá»‘i Æ°u cho WebRTC VAD)\n",
    "            padding_duration_ms: Padding trÆ°á»›c vÃ  sau speech\n",
    "            silence_duration_ms: Thá»i gian silence Ä‘á»ƒ káº¿t thÃºc segment\n",
    "            vad_sensitivity: Äá»™ nháº¡y cá»§a VAD (1-3, 3 lÃ  nháº¡y nháº¥t)\n",
    "        \"\"\"\n",
    "        self.sample_rate = sample_rate\n",
    "        self.chunk_duration_ms = chunk_duration_ms\n",
    "        self.chunk_size = int(sample_rate * chunk_duration_ms / 1000)\n",
    "        self.padding_duration_ms = padding_duration_ms\n",
    "        self.silence_duration_ms = silence_duration_ms\n",
    "        \n",
    "        # Initialize WebRTC VAD\n",
    "        self.vad = webrtcvad.Vad()\n",
    "        self.vad.set_mode(vad_sensitivity)\n",
    "\n",
    "        # Buffers\n",
    "        self.audio_buffer = deque(maxlen=32000)  # 2 seconds buffer\n",
    "        self.current_speech = []\n",
    "        self.speech_segments = queue.Queue()\n",
    "        \n",
    "        # State tracking\n",
    "        self.in_speech = False\n",
    "        self.silence_start = None\n",
    "        self.speech_start = None\n",
    "        self.processed_samples = 0\n",
    "\n",
    "        # Recording storage (full session) - will be written to WAV at the end (fallback)\n",
    "        self.recorded_samples = []  # store int16 samples\n",
    "\n",
    "        # Optional writer queue (started by higher-level class if streaming to disk)\n",
    "        self.audio_write_queue = None\n",
    "\n",
    "    #2. Audio Input Handler:\n",
    "    def _audio_callback(self, indata, frames, time, status):\n",
    "        \"\"\"Callback for sounddevice's InputStream\"\"\"\n",
    "        if status:\n",
    "            print(f\"Status: {status}\")\n",
    "            \n",
    "        # Convert to mono and correct format (int16)\n",
    "        audio_chunk = (indata[:, 0] * 32767).astype(np.int16)\n",
    "        \n",
    "        # Add to processing queue for VAD\n",
    "        self.audio_buffer.extend(audio_chunk)\n",
    "\n",
    "        # If an audio writer queue exists, push the chunk for streaming write\n",
    "        if getattr(self, 'audio_write_queue', None) is not None:\n",
    "            try:\n",
    "                # put a copy so further mutations don't affect queued data\n",
    "                self.audio_write_queue.put(audio_chunk.copy(), block=False)\n",
    "            except Exception:\n",
    "                # queue full or other issue - drop silently to avoid blocking audio thread\n",
    "                pass\n",
    "        \n",
    "        # Process complete chunks\n",
    "        while len(self.audio_buffer) >= self.chunk_size:\n",
    "            chunk = np.array([self.audio_buffer.popleft() \n",
    "                            for _ in range(self.chunk_size)])\n",
    "            self._process_chunk(chunk)\n",
    "\n",
    "    #3. VAD Processing Logic:\n",
    "    def _process_chunk(self, chunk: np.ndarray):\n",
    "        \"\"\"Process má»™t chunk audio vá»›i VAD\"\"\"\n",
    "        # Append to full recording buffer (keep as Python ints to avoid large numpy memory until write)\n",
    "        try:\n",
    "            self.recorded_samples.extend(chunk.tolist())\n",
    "        except Exception:\n",
    "            # Fallback: if extend fails for memory reasons, silently continue (still do VAD)\n",
    "            pass\n",
    "\n",
    "        is_speech = self.vad.is_speech(chunk.tobytes(), self.sample_rate)\n",
    "        current_time = self.processed_samples / self.sample_rate\n",
    "\n",
    "        if is_speech and not self.in_speech:\n",
    "            # Speech báº¯t Ä‘áº§u\n",
    "            self.in_speech = True\n",
    "            self.speech_start = max(0, current_time - self.padding_duration_ms/1000)\n",
    "            self.silence_start = None\n",
    "            \n",
    "            # Add padding tá»« buffer trÆ°á»›c Ä‘Ã³\n",
    "            padding_samples = int(self.padding_duration_ms * self.sample_rate / 1000)\n",
    "            if self.audio_buffer:\n",
    "                padding = list(self.audio_buffer)[-padding_samples:]\n",
    "                self.current_speech.extend(padding)\n",
    "            \n",
    "        elif not is_speech and self.in_speech:\n",
    "            # Potential end of speech\n",
    "            if self.silence_start is None:\n",
    "                self.silence_start = current_time\n",
    "                \n",
    "            # Check if silence Ä‘á»§ dÃ i\n",
    "            if (current_time - self.silence_start) > self.silence_duration_ms/1000:\n",
    "                self._finalize_speech_segment()\n",
    "                \n",
    "        # Collect samples náº¿u Ä‘ang trong speech segment\n",
    "        if self.in_speech:\n",
    "            self.current_speech.extend(chunk)\n",
    "            \n",
    "        self.processed_samples += len(chunk)\n",
    "\n",
    "    def _finalize_speech_segment(self):\n",
    "        \"\"\"Káº¿t thÃºc speech segment hiá»‡n táº¡i\"\"\"\n",
    "        if not self.current_speech:\n",
    "            return\n",
    "            \n",
    "        # Add post-speech padding\n",
    "        padding_samples = int(self.padding_duration_ms * self.sample_rate / 1000)\n",
    "        if self.audio_buffer:\n",
    "            padding = list(self.audio_buffer)[:padding_samples]\n",
    "            self.current_speech.extend(padding)\n",
    "        \n",
    "        # Create speech segment\n",
    "        segment = SpeechSegment(\n",
    "            samples=np.array(self.current_speech),\n",
    "            start_time=self.speech_start,\n",
    "            end_time=self.processed_samples / self.sample_rate,\n",
    "            confidence=0.9\n",
    "        )\n",
    "        \n",
    "        # Add to output queue\n",
    "        self.speech_segments.put(segment)\n",
    "        \n",
    "        # Reset state\n",
    "        self.current_speech = []\n",
    "        self.in_speech = False\n",
    "        self.speech_start = None\n",
    "        self.silence_start = None\n",
    "\n",
    "    #4. Main Recording Loop:\n",
    "    def start(self, duration: Optional[float] = None):\n",
    "        \"\"\"Báº¯t Ä‘áº§u recording vÃ  VAD processing\"\"\"\n",
    "        try:\n",
    "            with sd.InputStream(channels=1,\n",
    "                            samplerate=self.sample_rate,\n",
    "                            dtype=np.float32,\n",
    "                            callback=self._audio_callback,\n",
    "                            blocksize=self.chunk_size):\n",
    "                \n",
    "                print(f\"Started VAD recording (Press Ctrl+C to stop)\")\n",
    "                \n",
    "                start_time = time.time()\n",
    "                while True:\n",
    "                    # Check duration\n",
    "                    if duration and (time.time() - start_time) > duration:\n",
    "                        break\n",
    "                        \n",
    "                    # Process available speech segments\n",
    "                    try:\n",
    "                        segment = self.speech_segments.get_nowait()\n",
    "                        self._process_speech_segment(segment)\n",
    "                    except queue.Empty:\n",
    "                        time.sleep(0.1)\n",
    "                        continue\n",
    "                        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nRecording stopped.\")\n",
    "            \n",
    "    def _process_speech_segment(self, segment: SpeechSegment):\n",
    "        \"\"\"Process detected speech segment - Override trong subclass\"\"\"\n",
    "        duration = segment.end_time - segment.start_time\n",
    "        print(f\"Speech detected: {duration:.2f}s ({segment.start_time:.2f}s - {segment.end_time:.2f}s)\")\n",
    "        # CÃ³ thá»ƒ thÃªm xá»­ lÃ½ khÃ¡c á»Ÿ Ä‘Ã¢y (e.g., transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8369643",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranscriptionWorker:\n",
    "    def __init__(self, model_name: str = \"base\"):\n",
    "        self.model = whisper.load_model(model_name)\n",
    "        self.queue = queue.Queue()\n",
    "        self.results = queue.Queue()\n",
    "        self.running = True\n",
    "        self.thread = threading.Thread(target=self._process_loop)\n",
    "        self.thread.daemon = True\n",
    "        self.thread.start()\n",
    "    \n",
    "    def _process_loop(self):\n",
    "        while self.running:\n",
    "            try:\n",
    "                segment = self.queue.get(timeout=1)\n",
    "                \n",
    "                # Save temporary WAV file for Whisper\n",
    "                temp_file = f\"temp_{time.time()}.wav\"\n",
    "                sf.write(temp_file, segment.samples, 16000)\n",
    "                \n",
    "                try:\n",
    "                    # Transcribe with Whisper using FP32\n",
    "                    result = self.model.transcribe(temp_file, fp16=False)\n",
    "                    segment.transcript = result[\"text\"].strip()\n",
    "                    self.results.put(segment)\n",
    "                finally:\n",
    "                    # Cleanup temp file\n",
    "                    if os.path.exists(temp_file):\n",
    "                        os.remove(temp_file)\n",
    "                        \n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Transcription error: {e}\")\n",
    "    \n",
    "    def add_segment(self, segment: SpeechSegment):\n",
    "        self.queue.put(segment)\n",
    "    \n",
    "    def get_transcribed_segment(self, timeout: float = 0.1) -> Optional[SpeechSegment]:\n",
    "        try:\n",
    "            return self.results.get(timeout=timeout)\n",
    "        except queue.Empty:\n",
    "            return None\n",
    "    \n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        if self.thread.is_alive():\n",
    "            self.thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdb38a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example vá»›i realtime transcription vÃ  speaker diarization\n",
    "class TranscribingVAD(RealtimeVAD):\n",
    "    def __init__(self, *args, transcript_file=\"transcript.txt\", audio_file=\"recording.wav\", \n",
    "                 max_meeting_duration: Optional[float] = None, \n",
    "                 use_diarization: bool = True,\n",
    "                 auth_token: Optional[str] = None,  # Add auth token parameter\n",
    "                 **kwargs):\n",
    "        \"\"\"Transcribing VAD with speaker diarization.\n",
    "\n",
    "        Args:\n",
    "            transcript_file: path to write transcripts\n",
    "            audio_file: path to save full recording\n",
    "            max_meeting_duration: optional maximum meeting duration in seconds\n",
    "            use_diarization: whether to enable speaker diarization\n",
    "            auth_token: Hugging Face auth token for pyannote.audio\n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.transcriber = TranscriptionWorker(model_name=\"base\")\n",
    "        self.transcript_file = transcript_file\n",
    "        self.audio_file = audio_file\n",
    "        self.pending_transcripts = 0  # Äáº¿m sá»‘ transcript Ä‘ang chá» xá»­ lÃ½\n",
    "        self.max_meeting_duration = max_meeting_duration\n",
    "        # We'll attempt pyannote if requested and token provided; otherwise may fallback to local diarizer\n",
    "        self.use_diarization = use_diarization and auth_token is not None\n",
    "        self.auth_token = auth_token\n",
    "        \n",
    "        # Diarization state\n",
    "        self.pipeline = None\n",
    "        self.local_diarizer = None\n",
    "        self.diarization_cache = {}  # Cache diarization results by segment\n",
    "        self.min_segment_duration = 2.0  # Minimum segment duration for reliable diarization\n",
    "        self.long_segments = []  # Store longer segments for batch processing\n",
    "        \n",
    "        # Initialize speaker diarization if enabled\n",
    "        if self.use_diarization:\n",
    "            try:\n",
    "                print(\"Initializing speaker diarization pipeline (pyannote)...\")\n",
    "                # Prefer huggingface_hub.login when available\n",
    "                try:\n",
    "                    from huggingface_hub import login\n",
    "                except Exception:\n",
    "                    login = None\n",
    "\n",
    "                if self.auth_token:\n",
    "                    if login is not None:\n",
    "                        print(\"Logging into Hugging Face hub for diarization...\")\n",
    "                        login(self.auth_token)\n",
    "                    else:\n",
    "                        # Fallback: set env var for the process\n",
    "                        os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = self.auth_token\n",
    "\n",
    "                # Attempt to load pyannote pipeline, retry with revision='main' if necessary\n",
    "                from pyannote.audio import Pipeline as _Pipeline\n",
    "                try:\n",
    "                    self.pipeline = _Pipeline.from_pretrained(\"pyannote/speaker-diarization\")\n",
    "                except Exception as e:\n",
    "                    msg = str(e)\n",
    "                    if \"Revisions must be passed\" in msg or \"revision\" in msg:\n",
    "                        print(\"Caught revision-related error; retrying with revision='main'...\")\n",
    "                        try:\n",
    "                            self.pipeline = _Pipeline.from_pretrained(\"pyannote/speaker-diarization\", revision=\"main\")\n",
    "                        except Exception as e2:\n",
    "                            raise RuntimeError(f\"Failed to load pyannote pipeline with revision fallback: {e2}\")\n",
    "                    else:\n",
    "                        raise\n",
    "\n",
    "                print(\"Speaker diarization pipeline initialized successfully\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Speaker diarization initialization failed: {e}\")\n",
    "                print(\"Falling back to local diarizer if available (resemblyzer)...\")\n",
    "                self.pipeline = None\n",
    "                # Try to initialize local diarizer if possible\n",
    "                try:\n",
    "                    if VoiceEncoder is not None:\n",
    "                        self.local_diarizer = LocalDiarizer(sample_rate=self.sample_rate, similarity_threshold=0.70)\n",
    "                        print(\"Local diarizer (resemblyzer) initialized successfully\")\n",
    "                        # set flag to indicate diarization is enabled via local method\n",
    "                        self.use_diarization = True\n",
    "                    else:\n",
    "                        print(\"Local diarizer not available (resemblyzer missing), disabling diarization\")\n",
    "                        self.use_diarization = False\n",
    "                except Exception as e2:\n",
    "                    print(f\"Failed to initialize local diarizer: {e2}\")\n",
    "                    self.use_diarization = False\n",
    "                    self.local_diarizer = None\n",
    "        else:\n",
    "            # If diarization not requested or no auth token, try local diarizer if installed\n",
    "            if VoiceEncoder is not None:\n",
    "                try:\n",
    "                    self.local_diarizer = LocalDiarizer(sample_rate=self.sample_rate, similarity_threshold=0.70)\n",
    "                    print(\"Local diarizer (resemblyzer) initialized for offline diarization\")\n",
    "                    self.use_diarization = True\n",
    "                except Exception as e:\n",
    "                    print(f\"Local diarizer init failed: {e}\")\n",
    "                    self.local_diarizer = None\n",
    "            else:\n",
    "                self.local_diarizer = None\n",
    "\n",
    "        # Create transcript file with header\n",
    "        with open(self.transcript_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"=== Transcript File ===\\n\")\n",
    "            f.write(f\"Created: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            if self.max_meeting_duration:\n",
    "                f.write(f\"Max meeting duration (s): {self.max_meeting_duration}\\n\")\n",
    "            f.write(f\"Speaker diarization: {'Enabled' if self.use_diarization else 'Disabled'}\\n\")\n",
    "            if not self.use_diarization and use_diarization:\n",
    "                f.write(\"Note: Diarization requested but disabled due to missing auth token or failure to initialize\\n\")\n",
    "            f.write(\"====================\\n\\n\")\n",
    "\n",
    "        # writer thread state\n",
    "        self.audio_write_queue = None\n",
    "        self._audio_writer_thread = None\n",
    "        self._audio_writer_running = False\n",
    "        \n",
    "        # Cached speaker segments for diarization\n",
    "        self._speaker_segments = {}  # timestamp -> speaker_id\n",
    "        self._last_diarization_time = 0\n",
    "        self._diarization_interval = 30  # Process every 30 seconds\n",
    "    \n",
    "    def _identify_speaker(self, audio_segment: np.ndarray, start_time: float, end_time: float) -> str:\n",
    "        \"\"\"Identify speaker for an audio segment.\n",
    "        If pyannote pipeline is available, use it; otherwise use the local diarizer.\n",
    "        \"\"\"\n",
    "        if not self.use_diarization:\n",
    "            return \"UNKNOWN\"\n",
    "\n",
    "        # Prefer pyannote pipeline if present\n",
    "        if self.pipeline is not None:\n",
    "            try:\n",
    "                temp_file = f\"temp_diarize_{time.time()}.wav\"\n",
    "                sf.write(temp_file, audio_segment, self.sample_rate)\n",
    "                diarization = self.pipeline(temp_file)\n",
    "                speaker_id = \"UNKNOWN\"\n",
    "                max_overlap = 0\n",
    "                for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "                    overlap = min(turn.end, end_time) - max(turn.start, start_time)\n",
    "                    if overlap > max_overlap:\n",
    "                        speaker_id = speaker\n",
    "                        max_overlap = overlap\n",
    "                try:\n",
    "                    os.remove(temp_file)\n",
    "                except Exception:\n",
    "                    pass\n",
    "                return speaker_id or \"UNKNOWN\"\n",
    "            except Exception as e:\n",
    "                print(f\"pyannote identification failed for segment: {e}\")\n",
    "                # fall through to local diarizer if available\n",
    "\n",
    "        if self.local_diarizer is not None:\n",
    "            try:\n",
    "                return self.local_diarizer.identify(audio_segment)\n",
    "            except Exception as e:\n",
    "                print(f\"Local diarizer failed: {e}\")\n",
    "                return \"UNKNOWN\"\n",
    "\n",
    "        return \"UNKNOWN\"\n",
    "\n",
    "    def _process_speech_segment(self, segment: SpeechSegment):\n",
    "        \"\"\"Process a speech segment: identify speaker, transcribe, and save results\"\"\"\n",
    "        try:\n",
    "            # Get speaker ID\n",
    "            speaker_id = self._identify_speaker(segment.samples, segment.start_time, segment.end_time)\n",
    "            segment.speaker_id = speaker_id\n",
    "            \n",
    "            # Add to transcription queue\n",
    "            self.transcriber.add_segment(segment)\n",
    "            self.pending_transcripts += 1\n",
    "            \n",
    "            # Check for completed transcripts\n",
    "            while True:\n",
    "                result = self.transcriber.get_transcribed_segment(timeout=0.1)\n",
    "                if result is None:\n",
    "                    break\n",
    "                    \n",
    "                self.pending_transcripts -= 1\n",
    "                \n",
    "                # Write to transcript file\n",
    "                duration = result.end_time - result.start_time\n",
    "                with open(self.transcript_file, 'a', encoding='utf-8') as f:\n",
    "                    f.write(f\"\\n[{result.start_time:.1f}s -> {result.end_time:.1f}s] {result.speaker_id}: {result.transcript}\")\n",
    "                \n",
    "                # Print to console\n",
    "                print(f\"\\n[{duration:.1f}s] {result.speaker_id}: {result.transcript}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing segment: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6adfdd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalDiarizer:\n",
    "    def __init__(self, sample_rate: int = 16000, similarity_threshold: float = 0.75):\n",
    "        \"\"\"Initialize a local diarizer using resemblyzer voice embeddings.\n",
    "        \n",
    "        Args:\n",
    "            sample_rate: Audio sample rate (must match input)\n",
    "            similarity_threshold: Cosine similarity threshold for speaker matching (0.0-1.0)\n",
    "                                Lower values make it easier to detect different speakers\n",
    "        \"\"\"\n",
    "        self.sample_rate = sample_rate\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.speaker_embeddings = {}  # speaker_id -> embedding\n",
    "        self.next_speaker_id = 1\n",
    "        \n",
    "        # Load resemblyzer encoder\n",
    "        try:\n",
    "            from resemblyzer import VoiceEncoder\n",
    "            self.encoder = VoiceEncoder()\n",
    "            print(\"âœ“ Local diarizer: loaded resemblyzer encoder\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to initialize resemblyzer encoder: {e}\")\n",
    "    \n",
    "    def embed(self, audio: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Generate embedding for an audio segment.\"\"\"\n",
    "        # resemblyzer expects float32 in [-1, 1]\n",
    "        if audio.dtype == np.int16:\n",
    "            audio = audio.astype(np.float32) / 32767.0\n",
    "        return self.encoder.embed_utterance(audio)\n",
    "    \n",
    "    def identify(self, audio: np.ndarray) -> str:\n",
    "        \"\"\"Identify the speaker in an audio segment.\n",
    "        Returns speaker ID (e.g., \"SPEAKER_1\") or creates a new one if no match.\n",
    "        \"\"\"\n",
    "        # Get embedding for this segment\n",
    "        try:\n",
    "            embedding = self.embed(audio)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to generate embedding: {e}\")\n",
    "            return \"UNKNOWN\"\n",
    "            \n",
    "        # If no speakers yet, create first one\n",
    "        if not self.speaker_embeddings:\n",
    "            speaker_id = f\"SPEAKER_{self.next_speaker_id}\"\n",
    "            self.speaker_embeddings[speaker_id] = embedding\n",
    "            self.next_speaker_id += 1\n",
    "            return speaker_id\n",
    "            \n",
    "        # Compare with existing speakers\n",
    "        max_similarity = -1\n",
    "        best_speaker = None\n",
    "        \n",
    "        for speaker_id, spk_embedding in self.speaker_embeddings.items():\n",
    "            similarity = cosine_similarity(embedding.reshape(1, -1), spk_embedding.reshape(1, -1))[0, 0]\n",
    "            \n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                best_speaker = speaker_id\n",
    "                \n",
    "        # If similarity is high enough, use existing speaker\n",
    "        if max_similarity >= self.similarity_threshold:\n",
    "            # Update speaker embedding with running average\n",
    "            old_emb = self.speaker_embeddings[best_speaker]\n",
    "            self.speaker_embeddings[best_speaker] = 0.9 * old_emb + 0.1 * embedding\n",
    "            return best_speaker\n",
    "            \n",
    "        # Otherwise create new speaker\n",
    "        new_speaker = f\"SPEAKER_{self.next_speaker_id}\"\n",
    "        self.speaker_embeddings[new_speaker] = embedding\n",
    "        self.next_speaker_id += 1\n",
    "        return new_speaker\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Clear speaker history/embeddings.\"\"\"\n",
    "        self.speaker_embeddings.clear()\n",
    "        self.next_speaker_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2668f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export HUGGINGFACE_HUB_TOKEN=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2200c6",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "931e946a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting diarization system test...\n",
      "Testing diarization pipeline (pyannote preferred, local fallback)...\n",
      "pyannote pipeline initialization failed: Auth token not set. Set HUGGINGFACE_HUB_TOKEN environment variable or populate auth_token in the notebook.\n",
      "Falling back to local resemblyzer-based diarizer for test...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "âœ“ Local diarizer: loaded resemblyzer encoder\n",
      "Local diarizer IDs: seg1=SPEAKER_1, seg2=SPEAKER_2\n",
      "âœ“ Local diarizer produced different speaker IDs for the two test segments\n",
      "Local diarizer IDs: seg1=SPEAKER_1, seg2=SPEAKER_2\n",
      "âœ“ Local diarizer produced different speaker IDs for the two test segments\n"
     ]
    }
   ],
   "source": [
    "# Test thá»­ pyannote.audio pipeline (with revision fallback and local-diarizer fallback)\n",
    "def test_diarization():\n",
    "    try:\n",
    "        print(\"Testing diarization pipeline (pyannote preferred, local fallback)...\")\n",
    "\n",
    "        # Ensure VoiceEncoder is available in this scope (in case the Imports cell wasn't executed)\n",
    "        try:\n",
    "            VoiceEncoder  # reference to see if exists\n",
    "        except NameError:\n",
    "            try:\n",
    "                from resemblyzer import VoiceEncoder as _VoiceEncoder\n",
    "                VoiceEncoder = _VoiceEncoder\n",
    "            except Exception:\n",
    "                VoiceEncoder = None\n",
    "\n",
    "        # Helper to attempt Pipeline.from_pretrained with a revision fallback\n",
    "        def load_pyannote_pipeline():\n",
    "            try:\n",
    "                from pyannote.audio import Pipeline as _Pipeline\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"pyannote.audio not available: {e}\")\n",
    "\n",
    "            # Ensure auth is set\n",
    "            try:\n",
    "                from huggingface_hub import login as _login\n",
    "            except Exception:\n",
    "                _login = None\n",
    "\n",
    "            auth_token = os.environ.get(\"HUGGINGFACE_HUB_TOKEN\") or \"\"\n",
    "            if not auth_token:\n",
    "                raise ValueError(\"Auth token not set. Set HUGGINGFACE_HUB_TOKEN environment variable or populate auth_token in the notebook.\")\n",
    "\n",
    "            if _login is not None:\n",
    "                print(\"Logging into Hugging Face hub...\")\n",
    "                _login(auth_token)\n",
    "            else:\n",
    "                os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = auth_token\n",
    "\n",
    "            # Try loading pipeline; on specific revision error retry with revision='main'\n",
    "            try:\n",
    "                return _Pipeline.from_pretrained(\"pyannote/speaker-diarization\")\n",
    "            except Exception as e:\n",
    "                msg = str(e)\n",
    "                if \"Revisions must be passed\" in msg or \"revision\" in msg:\n",
    "                    print(\"Caught revision-related error from from_pretrained; retrying with revision='main'...\")\n",
    "                    try:\n",
    "                        return _Pipeline.from_pretrained(\"pyannote/speaker-diarization\", revision=\"main\")\n",
    "                    except Exception as e2:\n",
    "                        raise RuntimeError(f\"Failed to load pyannote pipeline with revision='main': {e2}\")\n",
    "                else:\n",
    "                    raise\n",
    "\n",
    "        pipeline = None\n",
    "        try:\n",
    "            pipeline = load_pyannote_pipeline()\n",
    "            print(\"âœ“ pyannote pipeline initialized successfully\")\n",
    "            use_pyannote = True\n",
    "        except Exception as e:\n",
    "            print(f\"pyannote pipeline initialization failed: {e}\")\n",
    "            use_pyannote = False\n",
    "\n",
    "        # Create a test audio file (two distinct tones -> two speakers)\n",
    "        import numpy as np\n",
    "        import soundfile as sf\n",
    "        sample_rate = 16000\n",
    "        duration = 5\n",
    "        t = np.linspace(0, duration, sample_rate * duration)\n",
    "        speaker1 = np.sin(2 * np.pi * 440 * t[:len(t)//2]) * 0.5\n",
    "        speaker2 = np.sin(2 * np.pi * 880 * t[len(t)//2:]) * 0.5\n",
    "        audio = np.concatenate([speaker1, np.zeros(int(0.1 * sample_rate)), speaker2])\n",
    "        noise = np.random.normal(0, 0.01, len(audio))\n",
    "        audio = audio + noise\n",
    "        test_file = \"diarization_test.wav\"\n",
    "        sf.write(test_file, audio, sample_rate)\n",
    "\n",
    "        if use_pyannote:\n",
    "            print(\"Running pyannote diarization on test file...\")\n",
    "            diarization = pipeline(test_file)\n",
    "            print(\"Diarization results (pyannote):\")\n",
    "            count = 0\n",
    "            total = 0.0\n",
    "            for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "                print(f\"[{turn.start:.1f}s -> {turn.end:.1f}s] {speaker}\")\n",
    "                count += 1\n",
    "                total += turn.end - turn.start\n",
    "            if count == 0:\n",
    "                raise RuntimeError(\"pyannote produced no speaker turns\")\n",
    "            print(f\"âœ“ pyannote diarization ok: {count} turns, {total:.1f}s total\")\n",
    "            return True\n",
    "        else:\n",
    "            # Fallback to local diarizer\n",
    "            if VoiceEncoder is None:\n",
    "                raise RuntimeError(\"Neither pyannote available nor resemblyzer installed. Install resemblyzer for local diarization: pip install resemblyzer sklearn\")\n",
    "            print(\"Falling back to local resemblyzer-based diarizer for test...\")\n",
    "            ld = LocalDiarizer(sample_rate=sample_rate, similarity_threshold=0.65)\n",
    "            # split test audio into two segments and identify\n",
    "            half = len(audio)//2\n",
    "            seg1 = (audio[:half]).astype(np.float32)\n",
    "            seg2 = (audio[half:]).astype(np.float32)\n",
    "            id1 = ld.identify((seg1 * 32767).astype(np.int16))\n",
    "            id2 = ld.identify((seg2 * 32767).astype(np.int16))\n",
    "            print(f\"Local diarizer IDs: seg1={id1}, seg2={id2}\")\n",
    "            if id1 == id2:\n",
    "                print(\"Warning: local diarizer assigned same speaker to both segments; consider lowering similarity_threshold\")\n",
    "            else:\n",
    "                print(\"âœ“ Local diarizer produced different speaker IDs for the two test segments\")\n",
    "            return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâœ— Diarization test failed: {e}\")\n",
    "        print(\"Troubleshooting tips:\")\n",
    "        print(\" - Ensure torch/torchaudio are installed and compatible\")\n",
    "        print(\" - If using pyannote, ensure HUGGINGFACE_HUB_TOKEN is set and you've accepted the model license on huggingface.co\")\n",
    "        print(\" - To use the local diarizer, install resemblyzer: pip install resemblyzer sklearn\")\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        if os.path.exists(test_file):\n",
    "            try:\n",
    "                os.remove(test_file)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "# Run the test\n",
    "print(\"Starting diarization system test...\")\n",
    "diarization_ok = test_diarization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98b1a9b",
   "metadata": {},
   "source": [
    "## RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670158ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TranscribingVAD instance...\n",
      "Initializing speaker diarization pipeline (pyannote)...\n",
      "Logging into Hugging Face hub for diarization...\n",
      "Initializing speaker diarization pipeline (pyannote)...\n",
      "Logging into Hugging Face hub for diarization...\n",
      "Caught revision-related error; retrying with revision='main'...\n",
      "Caught revision-related error; retrying with revision='main'...\n",
      "Warning: Speaker diarization initialization failed: Failed to load pyannote pipeline with revision fallback: Revisions must be passed with `revision` keyword argument.\n",
      "Falling back to local diarizer if available (resemblyzer)...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "âœ“ Local diarizer: loaded resemblyzer encoder\n",
      "Local diarizer (resemblyzer) initialized successfully\n",
      "Warning: Speaker diarization initialization failed: Failed to load pyannote pipeline with revision fallback: Revisions must be passed with `revision` keyword argument.\n",
      "Falling back to local diarizer if available (resemblyzer)...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "âœ“ Local diarizer: loaded resemblyzer encoder\n",
      "Local diarizer (resemblyzer) initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Create VAD instance with diarization if test passed\n",
    "if diarization_ok:\n",
    "    print(\"Creating TranscribingVAD instance...\")\n",
    "    vad = TranscribingVAD(\n",
    "        transcript_file=\"meeting_transcript.txt\",\n",
    "        audio_file=\"meeting_audio.wav\",\n",
    "        max_meeting_duration=60,  # 60 second test\n",
    "        use_diarization=True,\n",
    "        auth_token=os.environ.get(\"HUGGINGFACE_HUB_TOKEN\", \"\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2537fc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting VAD with diarization...\n",
      "Started VAD recording (Press Ctrl+C to stop)\n",
      "\n",
      "[2.2s] SPEAKER_2: BOT HIGH BABOT\n",
      "\n",
      "[2.2s] SPEAKER_2: BOT HIGH BABOT\n"
     ]
    }
   ],
   "source": [
    "# Only proceed if diarization test passed\n",
    "if diarization_ok:\n",
    "    print(\"Starting VAD with diarization...\")\n",
    "    try:\n",
    "        vad.start(duration=60)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nRecording stopped by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during recording: {e}\")\n",
    "    finally:\n",
    "        # Cleanup\n",
    "        if hasattr(vad, 'transcriber'):\n",
    "            vad.transcriber.stop()\n",
    "else:\n",
    "    print(\"Skipping run due to diarization test failure. Please fix the issues above first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
