{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4106e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cài đặt ffmpeg trên MacOS bằng homebrew\n",
    "!brew install -q ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "075d1d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q numpy sounddevice webrtcvad soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e06ce45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c72276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb9e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95569f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Cấu trúc file và dependencies:\n",
    "# realtime_vad.py\n",
    "import queue\n",
    "import threading\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "from collections import deque\n",
    "import webrtcvad\n",
    "import time\n",
    "import whisper\n",
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "@dataclass\n",
    "class SpeechSegment:\n",
    "    samples: np.ndarray\n",
    "    start_time: float\n",
    "    end_time: float\n",
    "    confidence: float\n",
    "    transcript: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8607bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealtimeVAD:\n",
    "    def __init__(self, \n",
    "                 sample_rate: int = 16000,\n",
    "                 chunk_duration_ms: int = 30,\n",
    "                 padding_duration_ms: int = 300,\n",
    "                 silence_duration_ms: int = 500,\n",
    "                 vad_sensitivity: int = 3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sample_rate: Phải là 16000 cho WebRTC VAD\n",
    "            chunk_duration_ms: Độ dài mỗi chunk (30ms là tối ưu cho WebRTC VAD)\n",
    "            padding_duration_ms: Padding trước và sau speech\n",
    "            silence_duration_ms: Thời gian silence để kết thúc segment\n",
    "            vad_sensitivity: Độ nhạy của VAD (1-3, 3 là nhạy nhất)\n",
    "        \"\"\"\n",
    "        self.sample_rate = sample_rate\n",
    "        self.chunk_duration_ms = chunk_duration_ms\n",
    "        self.chunk_size = int(sample_rate * chunk_duration_ms / 1000)\n",
    "        self.padding_duration_ms = padding_duration_ms\n",
    "        self.silence_duration_ms = silence_duration_ms\n",
    "        \n",
    "        # Initialize WebRTC VAD\n",
    "        self.vad = webrtcvad.Vad()\n",
    "        self.vad.set_mode(vad_sensitivity)\n",
    "\n",
    "        # Buffers\n",
    "        self.audio_buffer = deque(maxlen=32000)  # 2 seconds buffer\n",
    "        self.current_speech = []\n",
    "        self.speech_segments = queue.Queue()\n",
    "        \n",
    "        # State tracking\n",
    "        self.in_speech = False\n",
    "        self.silence_start = None\n",
    "        self.speech_start = None\n",
    "        self.processed_samples = 0\n",
    "\n",
    "        # Recording storage (full session) - will be written to WAV at the end (fallback)\n",
    "        self.recorded_samples = []  # store int16 samples\n",
    "\n",
    "        # Optional writer queue (started by higher-level class if streaming to disk)\n",
    "        self.audio_write_queue = None\n",
    "\n",
    "    #2. Audio Input Handler:\n",
    "    def _audio_callback(self, indata, frames, time, status):\n",
    "        \"\"\"Callback for sounddevice's InputStream\"\"\"\n",
    "        if status:\n",
    "            print(f\"Status: {status}\")\n",
    "            \n",
    "        # Convert to mono and correct format (int16)\n",
    "        audio_chunk = (indata[:, 0] * 32767).astype(np.int16)\n",
    "        \n",
    "        # Add to processing queue for VAD\n",
    "        self.audio_buffer.extend(audio_chunk)\n",
    "\n",
    "        # If an audio writer queue exists, push the chunk for streaming write\n",
    "        if getattr(self, 'audio_write_queue', None) is not None:\n",
    "            try:\n",
    "                # put a copy so further mutations don't affect queued data\n",
    "                self.audio_write_queue.put(audio_chunk.copy(), block=False)\n",
    "            except Exception:\n",
    "                # queue full or other issue - drop silently to avoid blocking audio thread\n",
    "                pass\n",
    "        \n",
    "        # Process complete chunks\n",
    "        while len(self.audio_buffer) >= self.chunk_size:\n",
    "            chunk = np.array([self.audio_buffer.popleft() \n",
    "                            for _ in range(self.chunk_size)])\n",
    "            self._process_chunk(chunk)\n",
    "\n",
    "    #3. VAD Processing Logic:\n",
    "    def _process_chunk(self, chunk: np.ndarray):\n",
    "        \"\"\"Process một chunk audio với VAD\"\"\"\n",
    "        # Append to full recording buffer (keep as Python ints to avoid large numpy memory until write)\n",
    "        try:\n",
    "            self.recorded_samples.extend(chunk.tolist())\n",
    "        except Exception:\n",
    "            # Fallback: if extend fails for memory reasons, silently continue (still do VAD)\n",
    "            pass\n",
    "\n",
    "        is_speech = self.vad.is_speech(chunk.tobytes(), self.sample_rate)\n",
    "        current_time = self.processed_samples / self.sample_rate\n",
    "\n",
    "        if is_speech and not self.in_speech:\n",
    "            # Speech bắt đầu\n",
    "            self.in_speech = True\n",
    "            self.speech_start = max(0, current_time - self.padding_duration_ms/1000)\n",
    "            self.silence_start = None\n",
    "            \n",
    "            # Add padding từ buffer trước đó\n",
    "            padding_samples = int(self.padding_duration_ms * self.sample_rate / 1000)\n",
    "            if self.audio_buffer:\n",
    "                padding = list(self.audio_buffer)[-padding_samples:]\n",
    "                self.current_speech.extend(padding)\n",
    "            \n",
    "        elif not is_speech and self.in_speech:\n",
    "            # Potential end of speech\n",
    "            if self.silence_start is None:\n",
    "                self.silence_start = current_time\n",
    "                \n",
    "            # Check if silence đủ dài\n",
    "            if (current_time - self.silence_start) > self.silence_duration_ms/1000:\n",
    "                self._finalize_speech_segment()\n",
    "                \n",
    "        # Collect samples nếu đang trong speech segment\n",
    "        if self.in_speech:\n",
    "            self.current_speech.extend(chunk)\n",
    "            \n",
    "        self.processed_samples += len(chunk)\n",
    "\n",
    "    def _finalize_speech_segment(self):\n",
    "        \"\"\"Kết thúc speech segment hiện tại\"\"\"\n",
    "        if not self.current_speech:\n",
    "            return\n",
    "            \n",
    "        # Add post-speech padding\n",
    "        padding_samples = int(self.padding_duration_ms * self.sample_rate / 1000)\n",
    "        if self.audio_buffer:\n",
    "            padding = list(self.audio_buffer)[:padding_samples]\n",
    "            self.current_speech.extend(padding)\n",
    "        \n",
    "        # Create speech segment\n",
    "        segment = SpeechSegment(\n",
    "            samples=np.array(self.current_speech),\n",
    "            start_time=self.speech_start,\n",
    "            end_time=self.processed_samples / self.sample_rate,\n",
    "            confidence=0.9\n",
    "        )\n",
    "        \n",
    "        # Add to output queue\n",
    "        self.speech_segments.put(segment)\n",
    "        \n",
    "        # Reset state\n",
    "        self.current_speech = []\n",
    "        self.in_speech = False\n",
    "        self.speech_start = None\n",
    "        self.silence_start = None\n",
    "\n",
    "    #4. Main Recording Loop:\n",
    "    def start(self, duration: Optional[float] = None):\n",
    "        \"\"\"Bắt đầu recording và VAD processing\"\"\"\n",
    "        try:\n",
    "            with sd.InputStream(channels=1,\n",
    "                            samplerate=self.sample_rate,\n",
    "                            dtype=np.float32,\n",
    "                            callback=self._audio_callback,\n",
    "                            blocksize=self.chunk_size):\n",
    "                \n",
    "                print(f\"Started VAD recording (Press Ctrl+C to stop)\")\n",
    "                \n",
    "                start_time = time.time()\n",
    "                while True:\n",
    "                    # Check duration\n",
    "                    if duration and (time.time() - start_time) > duration:\n",
    "                        break\n",
    "                        \n",
    "                    # Process available speech segments\n",
    "                    try:\n",
    "                        segment = self.speech_segments.get_nowait()\n",
    "                        self._process_speech_segment(segment)\n",
    "                    except queue.Empty:\n",
    "                        time.sleep(0.1)\n",
    "                        continue\n",
    "                        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nRecording stopped.\")\n",
    "            \n",
    "    def _process_speech_segment(self, segment: SpeechSegment):\n",
    "        \"\"\"Process detected speech segment - Override trong subclass\"\"\"\n",
    "        duration = segment.end_time - segment.start_time\n",
    "        print(f\"Speech detected: {duration:.2f}s ({segment.start_time:.2f}s - {segment.end_time:.2f}s)\")\n",
    "        # Có thể thêm xử lý khác ở đây (e.g., transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8369643",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranscriptionWorker:\n",
    "    def __init__(self, model_name: str = \"base\"):\n",
    "        self.model = whisper.load_model(model_name)\n",
    "        self.queue = queue.Queue()\n",
    "        self.results = queue.Queue()\n",
    "        self.running = True\n",
    "        self.thread = threading.Thread(target=self._process_loop)\n",
    "        self.thread.daemon = True\n",
    "        self.thread.start()\n",
    "    \n",
    "    def _process_loop(self):\n",
    "        while self.running:\n",
    "            try:\n",
    "                segment = self.queue.get(timeout=1)\n",
    "                \n",
    "                # Save temporary WAV file for Whisper\n",
    "                temp_file = f\"temp_{time.time()}.wav\"\n",
    "                sf.write(temp_file, segment.samples, 16000)\n",
    "                \n",
    "                try:\n",
    "                    # Transcribe with Whisper using FP32\n",
    "                    result = self.model.transcribe(temp_file, fp16=False)\n",
    "                    segment.transcript = result[\"text\"].strip()\n",
    "                    self.results.put(segment)\n",
    "                finally:\n",
    "                    # Cleanup temp file\n",
    "                    if os.path.exists(temp_file):\n",
    "                        os.remove(temp_file)\n",
    "                        \n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Transcription error: {e}\")\n",
    "    \n",
    "    def add_segment(self, segment: SpeechSegment):\n",
    "        self.queue.put(segment)\n",
    "    \n",
    "    def get_transcribed_segment(self, timeout: float = 0.1) -> Optional[SpeechSegment]:\n",
    "        try:\n",
    "            return self.results.get(timeout=timeout)\n",
    "        except queue.Empty:\n",
    "            return None\n",
    "    \n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        if self.thread.is_alive():\n",
    "            self.thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdb38a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example với realtime transcription\n",
    "class TranscribingVAD(RealtimeVAD):\n",
    "    def __init__(self, *args, transcript_file=\"transcript.txt\", audio_file=\"recording.wav\", max_meeting_duration: Optional[float] = None, **kwargs):\n",
    "        \"\"\"Transcribing VAD.\n",
    "\n",
    "        Args:\n",
    "            transcript_file: path to write transcripts\n",
    "            audio_file: path to save full recording\n",
    "            max_meeting_duration: optional maximum meeting duration in seconds\n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.transcriber = TranscriptionWorker(model_name=\"turbo\")\n",
    "        self.transcript_file = transcript_file\n",
    "        self.audio_file = audio_file\n",
    "        self.pending_transcripts = 0  # Đếm số transcript đang chờ xử lý\n",
    "        self.max_meeting_duration = max_meeting_duration\n",
    "        \n",
    "        # Create transcript file with header\n",
    "        with open(self.transcript_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"=== Transcript File ===\\n\")\n",
    "            f.write(f\"Created: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            if self.max_meeting_duration:\n",
    "                f.write(f\"Max meeting duration (s): {self.max_meeting_duration}\\n\")\n",
    "            f.write(\"====================\\n\\n\")\n",
    "    \n",
    "    def _save_transcript(self, segment: SpeechSegment):\n",
    "        \"\"\"Lưu transcript vào file với timestamp\"\"\"\n",
    "        # Use absolute times relative to program start would be ideal; for simplicity use hh:mm:ss.ms now\n",
    "        start_time = time.strftime('%H:%M:%S') + f\".{int((segment.start_time % 1) * 1000):03d}\"\n",
    "        end_time = time.strftime('%H:%M:%S') + f\".{int((segment.end_time % 1) * 1000):03d}\"\n",
    "        \n",
    "        with open(self.transcript_file, 'a', encoding='utf-8') as f:\n",
    "            f.write(f\"[{start_time} - {end_time}] {segment.transcript}\\n\")\n",
    "    \n",
    "    def _process_speech_segment(self, segment):\n",
    "        # Print speech detection\n",
    "        super()._process_speech_segment(segment)\n",
    "        \n",
    "        # Send for async transcription\n",
    "        self.transcriber.add_segment(segment)\n",
    "        self.pending_transcripts += 1  # Tăng số lượng transcript đang chờ\n",
    "        \n",
    "        # Check for completed transcriptions\n",
    "        while True:\n",
    "            result = self.transcriber.get_transcribed_segment(timeout=0.1)\n",
    "            if not result:\n",
    "                break\n",
    "            # In ra console\n",
    "            print(f\"Transcript [{result.start_time:.2f}s - {result.end_time:.2f}s]: {result.transcript}\")\n",
    "            # Lưu vào file\n",
    "            self._save_transcript(result)\n",
    "            self.pending_transcripts -= 1  # Giảm số lượng transcript đang chờ\n",
    "    \n",
    "    def _write_audio_file(self):\n",
    "        \"\"\"Write the full recorded samples to the configured WAV file.\"\"\"\n",
    "        try:\n",
    "            import os\n",
    "            print(f\"Attempting to write audio file to: {os.path.abspath(self.audio_file)}\")\n",
    "            if not hasattr(self, 'recorded_samples') or len(self.recorded_samples) == 0:\n",
    "                print(\"No recorded samples to write.\")\n",
    "                return\n",
    "            import soundfile as sf\n",
    "            samples_np = np.array(self.recorded_samples, dtype=np.int16)\n",
    "            print(f\"Number of samples to write: {len(samples_np)} (duration={len(samples_np)/self.sample_rate:.2f}s)\")\n",
    "            # soundfile expects float or int arrays; write as PCM 16\n",
    "            sf.write(self.audio_file, samples_np, self.sample_rate, subtype='PCM_16')\n",
    "            print(f\"Saved recording to {self.audio_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to write audio file with soundfile: {e}\")\n",
    "            # Fallback: try using wave module\n",
    "            try:\n",
    "                import wave, struct\n",
    "                samples_np = np.array(self.recorded_samples, dtype=np.int16)\n",
    "                with wave.open(self.audio_file, 'wb') as wf:\n",
    "                    wf.setnchannels(1)\n",
    "                    wf.setsampwidth(2)  # bytes\n",
    "                    wf.setframerate(self.sample_rate)\n",
    "                    wf.writeframes(samples_np.tobytes())\n",
    "                print(f\"Saved recording to {self.audio_file} using wave fallback\")\n",
    "            except Exception as e2:\n",
    "                print(f\"Fallback wave write failed: {e2}\")\n",
    "    \n",
    "    def start(self, duration: Optional[float] = None):\n",
    "        \"\"\"Override phương thức start để thêm xử lý chờ transcription và lưu audio\n",
    "\n",
    "        `duration` is a requested recording time (seconds). If `max_meeting_duration` was set\n",
    "        in the constructor, recording will stop no later than that value. If both are None, recording\n",
    "        continues until interrupted.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with sd.InputStream(channels=1,\n",
    "                            samplerate=self.sample_rate,\n",
    "                            dtype=np.float32,\n",
    "                            callback=self._audio_callback,\n",
    "                            blocksize=self.chunk_size):\n",
    "                \n",
    "                print(f\"Started VAD recording (Press Ctrl+C to stop)\")\n",
    "                \n",
    "                start_time = time.time()\n",
    "                # Compute absolute stop time based on duration and max_meeting_duration\n",
    "                requested_end = None\n",
    "                if duration is not None:\n",
    "                    requested_end = start_time + duration\n",
    "                max_end = None\n",
    "                if self.max_meeting_duration is not None:\n",
    "                    max_end = start_time + self.max_meeting_duration\n",
    "\n",
    "                while True:\n",
    "                    now = time.time()\n",
    "                    # Enforce requested duration\n",
    "                    if requested_end is not None and now >= requested_end:\n",
    "                        print(\"Reached requested duration, stopping recording loop.\")\n",
    "                        break\n",
    "                    # Enforce maximum meeting duration\n",
    "                    if max_end is not None and now >= max_end:\n",
    "                        print(\"Reached maximum meeting duration, stopping recording loop.\")\n",
    "                        break\n",
    "\n",
    "                    # Process available speech segments\n",
    "                    try:\n",
    "                        segment = self.speech_segments.get_nowait()\n",
    "                        self._process_speech_segment(segment)\n",
    "                    except queue.Empty:\n",
    "                        time.sleep(0.1)\n",
    "                        continue\n",
    "                \n",
    "                print(\"\\nRecording finished, waiting for pending transcriptions...\")\n",
    "                \n",
    "                # Chờ cho tất cả transcription hoàn thành\n",
    "                while self.pending_transcripts > 0:\n",
    "                    # Tiếp tục xử lý các transcription đang pending\n",
    "                    try:\n",
    "                        result = self.transcriber.get_transcribed_segment(timeout=0.1)\n",
    "                        if result:\n",
    "                            print(f\"Transcript [{result.start_time:.2f}s - {result.end_time:.2f}s]: {result.transcript}\")\n",
    "                            self._save_transcript(result)\n",
    "                            self.pending_transcripts -= 1\n",
    "                    except queue.Empty:\n",
    "                        continue\n",
    "                    \n",
    "                # After all transcriptions saved, write the full audio file\n",
    "                self._write_audio_file()\n",
    "                print(f\"All transcriptions completed. Results saved to {self.transcript_file}\")\n",
    "                        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nRecording stopped by user, waiting for pending transcriptions...\")\n",
    "            # Xử lý tương tự khi người dùng dừng recording\n",
    "            while self.pending_transcripts > 0:\n",
    "                try:\n",
    "                    result = self.transcriber.get_transcribed_segment(timeout=0.1)\n",
    "                    if result:\n",
    "                        print(f\"Transcript [{result.start_time:.2f}s - {result.end_time:.2f}s]: {result.transcript}\")\n",
    "                        self._save_transcript(result)\n",
    "                        self.pending_transcripts -= 1\n",
    "                except queue.Empty:\n",
    "                    continue\n",
    "            # Write audio file even if interrupted\n",
    "            self._write_audio_file()\n",
    "            print(f\"All transcriptions completed. Results saved to {self.transcript_file}\")\n",
    "    \n",
    "    def __del__(self):\n",
    "        if hasattr(self, 'transcriber'):\n",
    "            self.transcriber.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2537fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create và start VAD với transcription\n",
    "vad = TranscribingVAD(\n",
    "    sample_rate=16000,\n",
    "    chunk_duration_ms=30,\n",
    "    padding_duration_ms=300,\n",
    "    silence_duration_ms=500,\n",
    "    vad_sensitivity=3,\n",
    "    transcript_file=\"meeting_transcript.txt\",  # Specify output file\n",
    "    audio_file=\"meeting_recording.wav\"\n",
    ")\n",
    "\n",
    "# Run for 60 seconds\n",
    "vad.start(duration=60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
